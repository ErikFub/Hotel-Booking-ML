{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Helping Hotels in times of flexible bookings\n",
    "\n",
    "As the pandemic has changed the tourism industry, customers are more and more used to flexibility options and cancellations when it comes to hotel bookings. Hotels are therefore offering their customers more options when it comes to changing and cancelling an existing booking. However, this imposes cost to a hotel business, as rooms are reserved for a long time and then might be cancelled shortly in advance. This short time is often not enough to find a new, paying customer for the hotel room.\n",
    "\n",
    "Therefore hotels might use a concept that is already prevailent in airlines: Overbooking the rooms they actually have. By accepting more bookings than a hotel has rooms, it can make sure to be closer to full capacity utilization. However, this imposes the risk of not having rooms available and having to reject customers that have a reserved room. This would be a very bad situation. Therefore it can be very beneficial to build a Machine Learning model that successfully predicts whether a customer is likely to cancel their booking, enabling the hotels to overbook the optimal number of rooms. That is the goal of this work.\n",
    "\n",
    "### Select a performance measure\n",
    "\n",
    "Classification of singular bookings or regression of rate of cancellations?\n",
    "\n",
    "- What is the cost of False Positives (we predict cancel, but customers show up and we have filled the slot)? bad\n",
    "- What is the cost of False Negatives (we predict show up, but customers cancel and we miss to fill the slot)?\n",
    "- What is the gain of True Positives (we fill the slot and it works out fine)?\n",
    "- What happens for False negatives (nothing, I suppose)?\n",
    "\n",
    "--> What can we do with this information?\n",
    "- choose threshold according to a maximization of profit\n",
    "- create a custom metric to evaluate our models\n",
    "- create a custom loss function to build the models\n",
    "\n",
    "\n",
    "### Check the assumptions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Imports & Data Access"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import missingno\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "seed = 42"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exec_directory = os.getcwd()\n",
    "main_directory = \"Hotel-Booking-ML\"\n",
    "main_dir_path = exec_directory[:exec_directory.find(main_directory) + len(main_directory)]\n",
    "raw_data_files_location = f\"{main_dir_path}/data/raw\"\n",
    "df_all = pd.read_csv(f\"{raw_data_files_location}/hotel_booking.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a first step we'll drop the columns 'reservation_status' and 'reservation_status_date' as they include information on our label. The value 'canceled' in 'reservation_status' indicates the same as 'is_canceled', this obviously information we don't need and shouldn't feed into the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all.drop(columns = ['reservation_status', 'reservation_status_date' ], inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "missingno.matrix(df_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Missing values\n",
    "\n",
    "Luckily our dataset is complete for all features apart from agent and company. According to the data dictionary of the dataset these columns represent IDs of the agents and companies (in case of business travel) that made the bookings. Therefore it is likely that missing values do represent an information: a NA in 'company' indicates that the booking was not a business travel and a NA in 'agent' indicates that no agent was used for the booking, meaning that it was a direct booking.\n",
    "\n",
    "Therefore we'll use OneHot encoding later on, to understand if there is a correlation between company, agent and our labels. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data transformation and aggregation. \n",
    "\n",
    "Before starting with the EDA we'll transform arrival and booking date to datetime format and transform the type of children in order to facilitate subsequent code operations. <br> We'll also aggregate data by calculating the number of total nights and retrieving the total number of guests. The aim of this is to reduce the number of features by aggregating redundant / similar information."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all.dropna(subset=['children'], inplace=True)\n",
    "df_all['children'] = df_all['children'].astype(int)\n",
    "df_all = df_all.astype({\"country\": str})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Getting arrival and booking dates right\n",
    "month_mapping = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, 'July': 7,\n",
    "                         'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "df_all['arrival_date_month'] = df_all['arrival_date_month'].apply(lambda m: month_mapping[m])\n",
    "df_all['arrival_date'] = pd.to_datetime(dict(year = df_all.arrival_date_year, \n",
    "                                         month = df_all.arrival_date_month, \n",
    "                                         day = df_all.arrival_date_day_of_month))\n",
    "df_all['booking_date'] = df_all.apply(lambda r: r['arrival_date'] - timedelta(days=r['lead_time']), axis=1)\n",
    "df_all['booking_date_day_of_week'] = df_all['booking_date'].dt.weekday\n",
    "\n",
    "# Number of Guests\n",
    "df_all['guests'] = df_all['adults'] + df_all['children'] + df_all['babies']\n",
    "\n",
    "# Length of stay\n",
    "df_all['stay_total_nights'] = df_all['stays_in_weekend_nights'] + df_all['stays_in_week_nights']\n",
    "\n",
    "# Is Family\n",
    "df_all['is_family'] = np.where((df_all['children'] >= 1) | (df_all['babies'] >= 1), 1, 0)\n",
    "\n",
    "# Assigned room type changed from booked room type\n",
    "df_all['room_changed'] = np.where(df_all['reserved_room_type'] == df_all['assigned_room_type'], 0, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a second step, we split the data in a train and a test set before working on the data, because we don't want to influence our training and analysis by any information from the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df, df_test = train_test_split(df_all, test_size = 0.2, random_state = seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Exploratory Data Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We firstly split the EDA for categorical and numerical features, as we'll perform different analysis methods. \n",
    "\n",
    "There are two exceptions here: \n",
    "- We'll see binary variables (with 0 and 1) as a numerical feature, as it can be analyzed with the methdos we use for the 'true' numerical features.\n",
    "- The 'hotel' feature discribes whether the data is for a 'City Hotel' or a 'Resort Hotel', it will be analyzed in numerical features as well. This is because we want to identify if it is worth to split the data we have according to the hotel and build separate models for each of the hotels. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categorical_features = [ 'meal', 'country', 'market_segment', 'distribution_channel', \n",
    "                         'reserved_room_type', 'assigned_room_type', 'deposit_type', 'agent', 'company', \n",
    "                         'customer_type']\n",
    "\n",
    "df_num = df.drop(columns = categorical_features)\n",
    "\n",
    "categorical_features.append('is_canceled')\n",
    "df_cat = df[categorical_features]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Numerical features\n",
    "#### 2.1.1 Correlations\n",
    "\n",
    "First we'll take a lookt at collinearity in the data set, by pairplotting relevant features and calculating their correlations.\n",
    "\n",
    "Please note that we are only using aggregated features here and not the features we calculated these aggregated ones on. For example, it wouldn't make sense to check for collinearity in guests with adults, children or babies as these variables are obviously correlated and won't be used side by side in the model. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_num[['lead_time', 'arrival_date_month','days_in_waiting_list', 'adr', \n",
    "                          'required_car_parking_spaces', 'total_of_special_requests',\n",
    "                          'stay_total_nights', 'guests','previous_cancellations','previous_bookings_not_canceled','is_family']])\n",
    "plt.show(sns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_corr = pd.DataFrame(df_num[['lead_time', 'arrival_date_month','days_in_waiting_list', 'adr', \n",
    "                          'required_car_parking_spaces', 'total_of_special_requests',\n",
    "                          'stay_total_nights', 'guests','previous_cancellations','previous_bookings_not_canceled','is_family']].corr().unstack()).rename({0: 'correlation'}, axis=1)\n",
    "df_corr[df_corr['correlation'] != 1].sort_values(by='correlation')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The highest correlation among our features is the correlation of ADR (revenue per day) with the number of guests, this follows the logic that with the more people you stay in a hotel, the more you'll spend. When building the model we'll take a closer look if this becomes a problem. For the other features the correlations are really small and therefore no worry.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, lets get the correlations of the **label** with the features, separately for the resort and city hotel to find out if they differ substiantially. This will be interesting when deciding whether to build separate models or not. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlations_all = df_num.corr()['is_canceled'].sort_values(ascending=False)\n",
    "correlations_city = df_num[df_num['hotel'] == 'City Hotel'].corr()['is_canceled']\n",
    "correlations_resort = df_num[df_num['hotel'] == 'Resort Hotel'].corr()['is_canceled']\n",
    "correlations_df = correlations_all.to_frame().rename({'is_canceled': \"All\"}, axis=1)\n",
    "correlations_df = correlations_df.join(correlations_city).rename({'is_canceled': \"City\"}, axis=1)\n",
    "correlations_df = correlations_df.join(correlations_resort).rename({'is_canceled': \"Resort\"}, axis=1)\n",
    "correlations_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This already gives a good indication, but let's plot the data to make the difference easier to understand."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlations_plot_df = pd.melt(correlations_df.drop('is_canceled'), ignore_index=False, var_name=\"Hotel\", value_name=\"Correlation\")\n",
    "correlations_plot_df['Variable'] = correlations_plot_df.index\n",
    "sns.catplot(data=correlations_plot_df, kind='bar', x='Variable', y='Correlation', hue='Hotel', aspect=2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Correlations by hotels')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This bar-chart shows that lead_time, previous_canellations, total_of_special_requests, required_car_parking_space and booking_changes have a correlation that is higher than 0.1 (in absolute terms). These are important candidates for our ML model later on. Additionally, the chart shows that for some features the correlation heavily depends on the kind of hotel we are looking at: For example, the number of total special requests is highly correlated with the cancellations at the city hotel, but not so much at the resort hotel. \n",
    "\n",
    "Based on this observation we will try out when building our first models, wether separate models or a joint model for both hotels performs better. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As booking changes cumulates over time the dataset doesn't include the information when the last change was made, we will not use it in our model. By this we prevent information that might have appeared just days before the arrival from influencing our model whith wich we want to predict cancelations at least 7 days before (the exact number will be deiced later on). \n",
    "\n",
    "Some numeric variables can also be used in binary form, which could benefit the model's performance. In order to find out which option should be picked, we will look at the correlations with the target variable is_canceled. Let's first look at total_of_special requests."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_corrcheck = df\n",
    "df_corrcheck['any_requests'] = df_corrcheck.total_of_special_requests.apply(lambda x: 1 if x > 0 else 0)\n",
    "df_corrcheck[['is_canceled', 'any_requests', 'total_of_special_requests']].corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the binary variable any_requests is more correlated with is_canceled, we will choose this option later on. Now let's inspect previous_canellations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_corrcheck['any_cancelations'] = df_corrcheck.previous_cancellations.apply(lambda x: 1 if x > 0 else 0)\n",
    "df_corrcheck[['is_canceled', 'any_cancelations', 'previous_cancellations']].corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This correlation is significantly higher in binary form. We will therefore use it in our model. Next up: required_car_parking_spaces."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_corrcheck['any_parking'] = df_corrcheck.required_car_parking_spaces.apply(lambda x: 1 if x > 0 else 0)\n",
    "df_corrcheck[['is_canceled', 'any_parking', 'required_car_parking_spaces']].corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is only little difference between the binary and the numeric column. We will go for the binary variable to keep the model simpler."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.2 Frequency Distributions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_num.hist(bins=50, figsize=(25,15))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(df['booking_date_day_of_week'])\n",
    "plt.show(sns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(df['hotel'])\n",
    "plt.show(sns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(df['lead_time'])\n",
    "plt.show(sns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Categorical variables\n",
    "\n",
    "#### 2.2.1 Understanding the categories\n",
    "\n",
    "Here we'll use df_cat, with all categorical features we have identified perviously. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "'Company' and 'agent' are columns with ids. Let's look at the values in the other (\"true\") categorical variables to get a feeling for what they are. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat[['meal']].value_counts(normalize = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat[['country']].value_counts(normalize = True).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat[['market_segment']].value_counts(normalize = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat[['distribution_channel']].value_counts(normalize = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat[['reserved_room_type']].value_counts(normalize = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat[['assigned_room_type']].value_counts(normalize = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat[['deposit_type']].value_counts(normalize = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat[['customer_type']].value_counts(normalize = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Especially, the deposit type seems likely to have a high explanatory power. If you have made no deposit you are much more likely to cancel a booking than when you made a non-refundable deposit, right?\n",
    "\n",
    "#### 2.2.2 Correlations of categorical variables with cancellations\n",
    "\n",
    "Let's OneHot Encode the categories and IDs (for agent and company) in the next step and get their correlations with the cancellations. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder(sparse = False)\n",
    "df_cat = df_cat.sort_index().reset_index(drop = True)\n",
    "df_cat_trans = pd.DataFrame(data = onehot.fit_transform(df_cat.drop(columns = 'is_canceled')),\n",
    "                                columns = onehot.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat_trans = pd.concat([df_cat.is_canceled, df_cat_trans], axis = 1 )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll use this transformed dataframe of our categorical variables and find out how correlated they are with 'is_canceled'.\n",
    "\n",
    "Watch out, the next cell takes quite a while to compute. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat_corr = df_cat_trans.corr()\n",
    "df_cat_corr = df_cat_corr['is_canceled']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat_corr.sort_values()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is gives a dataframe of **xxxx** correlations with the label. Very likely, most of them will have a very low correlation with the label. Therefore, let's only look at the ones with a correlation of more than 0.05 (positive or negative)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cat_corr_red = pd.DataFrame(df_cat_corr).rename({'is_canceled' : 'correlation'}, axis = 1)\n",
    "df_cat_corr_red = df_cat_corr_red[(df_cat_corr_red['correlation'] >= 0.1 ) | (df_cat_corr_red['correlation'] <= -0.1) ]\n",
    "df_cat_corr_red.sort_values(by = 'correlation')[:-1].plot(kind = 'bar')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us a good indication, that especially x2 (= 'deposit_type') is likely to have a high explanatory power. But also x1 = ('Coutnry') equalling to Portugal, x2 (= 'market_segment') equalling to Groups can be important when building the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Time Series Analysis\n",
    "In this section we are looking for underlying seasonality in the given cancelations and bookings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_resort = df[df[\"hotel\"] == \"Resort Hotel\"]\n",
    "df_city = df[df[\"hotel\"] == \"City Hotel\"]\n",
    "\n",
    "#Get data for Resort Hotel\n",
    "df_timeseries_r = pd.DataFrame(df_resort.groupby(\"arrival_date_month\").size())\n",
    "df_timeseries_r[\"Cancelations\"] = df_resort.groupby(\"arrival_date_month\")[\"is_canceled\"].sum()\n",
    "df_timeseries_r.columns = ['Arrivals', 'Cancelations']\n",
    "df_timeseries_r[\"Cancelation_Share\"] = df_timeseries_r[\"Cancelations\"]/df_timeseries_r[\"Arrivals\"]\n",
    "\n",
    "#Get data for City Hotel\n",
    "df_timeseries_c = pd.DataFrame(df_city.groupby(\"arrival_date_month\").size())\n",
    "df_timeseries_c[\"Cancelations\"] = df_city.groupby(\"arrival_date_month\")[\"is_canceled\"].sum()\n",
    "df_timeseries_c.columns = ['Arrivals', 'Cancelations']\n",
    "df_timeseries_c[\"Cancelation_Share\"] = df_timeseries_c[\"Cancelations\"]/df_timeseries_c[\"Arrivals\"]\n",
    "\n",
    "#Plot linechart\n",
    "fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "ax1.set_xlabel(\"Month\")\n",
    "ax1.set_ylabel(\"Number of Reservations\")\n",
    "ax1.plot(\n",
    "    df_timeseries_r[\"Arrivals\"],\n",
    "    color=\"red\",\n",
    "    label=\"Arrivals (Resort)\"\n",
    ")\n",
    "\n",
    "ax1.plot(\n",
    "    df_timeseries_c[\"Arrivals\"],\n",
    "    color=\"green\",\n",
    "    label=\"Arrivals (City)\"\n",
    ")\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "ax2.set_ylabel(\"Rate of Cancelations\")\n",
    "ax2.plot(\n",
    "    df_timeseries_r[\"Cancelation_Share\"],\n",
    "    color=\"red\",\n",
    "    linestyle=\"dashed\",\n",
    "    label=\"Rate of Cancelations (Resort)\",\n",
    ")\n",
    "\n",
    "ax2.plot(\n",
    "    df_timeseries_c[\"Cancelation_Share\"],\n",
    "    color=\"green\",\n",
    "    linestyle=\"dashed\",\n",
    "    label=\"Rate of Cancelations (City)\",\n",
    ")\n",
    "\n",
    "fig.legend(loc = 2, borderaxespad=9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on this plot, we can draw several conclusions:\n",
    "\n",
    "- Bookings and cancelation-rate differs greatly between Resort and City Hotels. With City Hotels experiencing more bookings but also more cancellations.\n",
    "- Cancellation rate follows the same patten as the number of bookings.\n",
    "- Bookings and cancellations follow a seasonal pattern."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Preliminary Model Selection\n",
    "Before going deeper into feature selection, we want to understand which model is the most promising for our task. For this model, more sophisticated feature selection will be conducted. We will test 5 different models:\n",
    "1. Logistic Regression\n",
    "2. Random Forest Classifier\n",
    "3. XGBoost Classifier\n",
    "4. Support Vector Machine\n",
    "5. Artificial Neural Network\n",
    "\n",
    "### 3.1 Feature Selection Pipeline\n",
    "Before testing the models, we need to build a pipeline in which all features get transformed into a format the models can best work with. Numerical features are standard scaled. For the categorical features, dimensions with less than 5% occurrences are aggregated in a 'other' category. Subsequently, categories are one-hot-encoded. The features *booking_changes* and *deposit_type* are excluded from the feature selection due to their inadequateness depicted in *2*."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Binarizer, FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "\n",
    "num_features = ['lead_time', 'adr', 'arrival_date_month', 'arrival_date_week_number', 'arrival_date_day_of_month', 'stays_in_week_nights', 'stays_in_weekend_nights', 'stay_total_nights', 'adults', 'children', 'babies', 'is_repeated_guest', 'previous_cancellations', 'previous_bookings_not_canceled', 'days_in_waiting_list', 'total_of_special_requests', 'room_changed']\n",
    "\n",
    "cat_features = ['hotel', 'meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'customer_type']\n",
    "\n",
    "class replace_other(TransformerMixin):\n",
    "    \"\"\"Replaces every value that accounts for less than 5% of the count of all unique\n",
    "    values in the column with 'Other'\"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "\n",
    "    def transform(self, df):\n",
    "        for col in df.columns:\n",
    "            counts = df[col].value_counts(normalize=True)\n",
    "            irrelevant = counts[counts < 0.05].index.tolist()\n",
    "            df[col] = df[col].apply(lambda v: 'Other' if v in irrelevant else v)\n",
    "        return df\n",
    "\n",
    "    def get_feature_names_out(self, col_names):\n",
    "        return col_names\n",
    "\n",
    "cat_selection_pipeline = Pipeline(steps=[\n",
    "    ('replace_other', replace_other()),\n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "feature_selection_pipeline = ColumnTransformer(transformers=[\n",
    "    ('numeric', StandardScaler(), num_features),\n",
    "    ('categorical', cat_selection_pipeline, cat_features)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "       numeric__lead_time  numeric__adr  numeric__arrival_date_month  \\\n0                0.542409     -0.427015                    -0.502248   \n1               -0.364575      1.628262                     0.144601   \n2                1.402640     -0.113830                     0.791450   \n3                1.374589     -0.237146                    -0.502248   \n4               -0.757289     -1.162413                    -1.472522   \n...                   ...           ...                          ...   \n95503           -0.944296      0.081911                     0.468026   \n95504           -0.345874      0.121059                    -0.825673   \n95505           -0.009262      0.219908                     1.761724   \n95506            0.243198      0.367692                     0.468026   \n95507           -0.822742      0.355948                     0.144601   \n\n       numeric__arrival_date_week_number  numeric__arrival_date_day_of_month  \\\n0                              -0.673372                           -1.113991   \n1                               0.061288                           -0.658664   \n2                               0.869414                            0.934982   \n3                              -0.452974                            0.593486   \n4                              -1.481498                            0.251991   \n...                                  ...                                 ...   \n95503                           0.502084                            0.479654   \n95504                          -0.820304                            0.707318   \n95505                           1.897937                            1.276477   \n95506                           0.281686                           -1.683151   \n95507                           0.281686                            1.731805   \n\n       numeric__stays_in_week_nights  numeric__stays_in_weekend_nights  \\\n0                          -0.786595                          1.077020   \n1                          -0.786595                          0.074652   \n2                          -0.786595                          0.074652   \n3                           0.788563                          1.077020   \n4                          -0.786595                          0.074652   \n...                              ...                               ...   \n95503                      -0.786595                         -0.927716   \n95504                      -0.786595                          1.077020   \n95505                       0.263510                         -0.927716   \n95506                       1.313616                          1.077020   \n95507                      -0.261542                         -0.927716   \n\n       numeric__stay_total_nights  numeric__adults  numeric__children  ...  \\\n0                       -0.165988        -1.498383          -0.260381  ...   \n1                       -0.557793         0.251740           4.764054  ...   \n2                       -0.557793         0.251740          -0.260381  ...   \n3                        1.009425         0.251740          -0.260381  ...   \n4                       -0.557793         0.251740          -0.260381  ...   \n...                           ...              ...                ...  ...   \n95503                   -0.949597         0.251740           2.251837  ...   \n95504                   -0.165988         0.251740          -0.260381  ...   \n95505                   -0.165988         2.001863          -0.260381  ...   \n95506                    1.401230         0.251740          -0.260381  ...   \n95507                   -0.557793        -1.498383          -0.260381  ...   \n\n       categorical__reserved_room_type_D  categorical__reserved_room_type_E  \\\n0                                    0.0                                0.0   \n1                                    0.0                                1.0   \n2                                    0.0                                0.0   \n3                                    0.0                                1.0   \n4                                    1.0                                0.0   \n...                                  ...                                ...   \n95503                                0.0                                0.0   \n95504                                0.0                                0.0   \n95505                                0.0                                1.0   \n95506                                0.0                                0.0   \n95507                                0.0                                0.0   \n\n       categorical__reserved_room_type_Other  \\\n0                                        0.0   \n1                                        0.0   \n2                                        0.0   \n3                                        0.0   \n4                                        0.0   \n...                                      ...   \n95503                                    0.0   \n95504                                    0.0   \n95505                                    0.0   \n95506                                    0.0   \n95507                                    0.0   \n\n       categorical__assigned_room_type_A  categorical__assigned_room_type_D  \\\n0                                    1.0                                0.0   \n1                                    0.0                                0.0   \n2                                    1.0                                0.0   \n3                                    0.0                                0.0   \n4                                    0.0                                1.0   \n...                                  ...                                ...   \n95503                                0.0                                1.0   \n95504                                1.0                                0.0   \n95505                                0.0                                0.0   \n95506                                1.0                                0.0   \n95507                                1.0                                0.0   \n\n       categorical__assigned_room_type_E  \\\n0                                    0.0   \n1                                    1.0   \n2                                    0.0   \n3                                    1.0   \n4                                    0.0   \n...                                  ...   \n95503                                0.0   \n95504                                0.0   \n95505                                1.0   \n95506                                0.0   \n95507                                0.0   \n\n       categorical__assigned_room_type_Other  \\\n0                                        0.0   \n1                                        0.0   \n2                                        0.0   \n3                                        0.0   \n4                                        0.0   \n...                                      ...   \n95503                                    0.0   \n95504                                    0.0   \n95505                                    0.0   \n95506                                    0.0   \n95507                                    0.0   \n\n       categorical__customer_type_Other  categorical__customer_type_Transient  \\\n0                                   0.0                                   1.0   \n1                                   0.0                                   1.0   \n2                                   0.0                                   1.0   \n3                                   0.0                                   1.0   \n4                                   0.0                                   1.0   \n...                                 ...                                   ...   \n95503                               0.0                                   1.0   \n95504                               0.0                                   1.0   \n95505                               0.0                                   1.0   \n95506                               0.0                                   1.0   \n95507                               0.0                                   0.0   \n\n       categorical__customer_type_Transient-Party  \n0                                             0.0  \n1                                             0.0  \n2                                             0.0  \n3                                             0.0  \n4                                             0.0  \n...                                           ...  \n95503                                         0.0  \n95504                                         0.0  \n95505                                         0.0  \n95506                                         0.0  \n95507                                         1.0  \n\n[95508 rows x 49 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>numeric__lead_time</th>\n      <th>numeric__adr</th>\n      <th>numeric__arrival_date_month</th>\n      <th>numeric__arrival_date_week_number</th>\n      <th>numeric__arrival_date_day_of_month</th>\n      <th>numeric__stays_in_week_nights</th>\n      <th>numeric__stays_in_weekend_nights</th>\n      <th>numeric__stay_total_nights</th>\n      <th>numeric__adults</th>\n      <th>numeric__children</th>\n      <th>...</th>\n      <th>categorical__reserved_room_type_D</th>\n      <th>categorical__reserved_room_type_E</th>\n      <th>categorical__reserved_room_type_Other</th>\n      <th>categorical__assigned_room_type_A</th>\n      <th>categorical__assigned_room_type_D</th>\n      <th>categorical__assigned_room_type_E</th>\n      <th>categorical__assigned_room_type_Other</th>\n      <th>categorical__customer_type_Other</th>\n      <th>categorical__customer_type_Transient</th>\n      <th>categorical__customer_type_Transient-Party</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.542409</td>\n      <td>-0.427015</td>\n      <td>-0.502248</td>\n      <td>-0.673372</td>\n      <td>-1.113991</td>\n      <td>-0.786595</td>\n      <td>1.077020</td>\n      <td>-0.165988</td>\n      <td>-1.498383</td>\n      <td>-0.260381</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.364575</td>\n      <td>1.628262</td>\n      <td>0.144601</td>\n      <td>0.061288</td>\n      <td>-0.658664</td>\n      <td>-0.786595</td>\n      <td>0.074652</td>\n      <td>-0.557793</td>\n      <td>0.251740</td>\n      <td>4.764054</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.402640</td>\n      <td>-0.113830</td>\n      <td>0.791450</td>\n      <td>0.869414</td>\n      <td>0.934982</td>\n      <td>-0.786595</td>\n      <td>0.074652</td>\n      <td>-0.557793</td>\n      <td>0.251740</td>\n      <td>-0.260381</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.374589</td>\n      <td>-0.237146</td>\n      <td>-0.502248</td>\n      <td>-0.452974</td>\n      <td>0.593486</td>\n      <td>0.788563</td>\n      <td>1.077020</td>\n      <td>1.009425</td>\n      <td>0.251740</td>\n      <td>-0.260381</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.757289</td>\n      <td>-1.162413</td>\n      <td>-1.472522</td>\n      <td>-1.481498</td>\n      <td>0.251991</td>\n      <td>-0.786595</td>\n      <td>0.074652</td>\n      <td>-0.557793</td>\n      <td>0.251740</td>\n      <td>-0.260381</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95503</th>\n      <td>-0.944296</td>\n      <td>0.081911</td>\n      <td>0.468026</td>\n      <td>0.502084</td>\n      <td>0.479654</td>\n      <td>-0.786595</td>\n      <td>-0.927716</td>\n      <td>-0.949597</td>\n      <td>0.251740</td>\n      <td>2.251837</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95504</th>\n      <td>-0.345874</td>\n      <td>0.121059</td>\n      <td>-0.825673</td>\n      <td>-0.820304</td>\n      <td>0.707318</td>\n      <td>-0.786595</td>\n      <td>1.077020</td>\n      <td>-0.165988</td>\n      <td>0.251740</td>\n      <td>-0.260381</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95505</th>\n      <td>-0.009262</td>\n      <td>0.219908</td>\n      <td>1.761724</td>\n      <td>1.897937</td>\n      <td>1.276477</td>\n      <td>0.263510</td>\n      <td>-0.927716</td>\n      <td>-0.165988</td>\n      <td>2.001863</td>\n      <td>-0.260381</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95506</th>\n      <td>0.243198</td>\n      <td>0.367692</td>\n      <td>0.468026</td>\n      <td>0.281686</td>\n      <td>-1.683151</td>\n      <td>1.313616</td>\n      <td>1.077020</td>\n      <td>1.401230</td>\n      <td>0.251740</td>\n      <td>-0.260381</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95507</th>\n      <td>-0.822742</td>\n      <td>0.355948</td>\n      <td>0.144601</td>\n      <td>0.281686</td>\n      <td>1.731805</td>\n      <td>-0.261542</td>\n      <td>-0.927716</td>\n      <td>-0.557793</td>\n      <td>-1.498383</td>\n      <td>-0.260381</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>95508 rows × 49 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selection_df = pd.DataFrame(data=feature_selection_pipeline.fit_transform(df), columns=feature_selection_pipeline.get_feature_names_out())\n",
    "feature_selection_test_df = pd.DataFrame(data=feature_selection_pipeline.fit_transform(df_test), columns=feature_selection_pipeline.get_feature_names_out())\n",
    "feature_selection_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Recursive Feature Elimination\n",
    "As we can see, the resulting number of features is 49. This number might be too high for some models. In order to best compare them, we'll eliminate the unimportant features so that for each model only the top 15 are left. An exception form the SVM and ANN. Here, since feature reduction is less straight forward than for the other models, we take the top 15 features that appear most times within the other models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikf\\Desktop\\Master BA\\S2\\Machine Learning\\Hotel-Booking-ML\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:35:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Logistic Regression': ['numeric__lead_time',\n  'numeric__arrival_date_month',\n  'numeric__arrival_date_week_number',\n  'numeric__previous_cancellations',\n  'numeric__previous_bookings_not_canceled',\n  'numeric__total_of_special_requests',\n  'numeric__room_changed',\n  'categorical__country_DEU',\n  'categorical__country_PRT',\n  'categorical__market_segment_Direct',\n  'categorical__market_segment_Groups',\n  'categorical__market_segment_Online TA',\n  'categorical__distribution_channel_Other',\n  'categorical__reserved_room_type_Other',\n  'categorical__customer_type_Transient'],\n 'Random Forest Classifier': ['numeric__lead_time',\n  'numeric__adr',\n  'numeric__arrival_date_month',\n  'numeric__arrival_date_week_number',\n  'numeric__arrival_date_day_of_month',\n  'numeric__stays_in_week_nights',\n  'numeric__stay_total_nights',\n  'numeric__previous_cancellations',\n  'numeric__total_of_special_requests',\n  'numeric__room_changed',\n  'categorical__country_PRT',\n  'categorical__market_segment_Groups',\n  'categorical__market_segment_Online TA',\n  'categorical__customer_type_Transient',\n  'categorical__customer_type_Transient-Party'],\n 'XGBoost Classifier': ['numeric__lead_time',\n  'numeric__previous_cancellations',\n  'numeric__previous_bookings_not_canceled',\n  'numeric__total_of_special_requests',\n  'numeric__room_changed',\n  'categorical__country_DEU',\n  'categorical__country_PRT',\n  'categorical__market_segment_Direct',\n  'categorical__market_segment_Groups',\n  'categorical__market_segment_Offline TA/TO',\n  'categorical__market_segment_Online TA',\n  'categorical__distribution_channel_Direct',\n  'categorical__customer_type_Other',\n  'categorical__customer_type_Transient',\n  'categorical__customer_type_Transient-Party'],\n 'Highest Frequency': ['numeric__lead_time',\n  'numeric__room_changed',\n  'categorical__customer_type_Transient',\n  'categorical__market_segment_Groups',\n  'categorical__country_PRT',\n  'categorical__market_segment_Online TA',\n  'numeric__total_of_special_requests',\n  'numeric__previous_cancellations',\n  'numeric__arrival_date_month',\n  'categorical__customer_type_Transient-Party',\n  'categorical__country_DEU',\n  'numeric__arrival_date_week_number',\n  'categorical__market_segment_Direct',\n  'numeric__previous_bookings_not_canceled',\n  'categorical__distribution_channel_Other']}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from typing import Dict, List\n",
    "\n",
    "top_features: Dict[str, List[str]] = {}\n",
    "\n",
    "estimators: Dict[str, dict] = {\n",
    "    'Logistic Regression': {'model': LogisticRegression(max_iter=300),\n",
    "                            'rfe_possible': True},\n",
    "    'Random Forest Classifier': {'model': RandomForestClassifier(),\n",
    "                                 'rfe_possible': True},\n",
    "    'XGBoost Classifier': {'model': XGBClassifier(objective='binary:logistic', use_label_encoder=False),\n",
    "                           'rfe_possible': True},\n",
    "    'SVM': {'model': SVC(probability=True),\n",
    "            'rfe_possible': False}\n",
    "}  # Artificial Neural Network will be considered separately under 3.3.2\n",
    "\n",
    "for estimator in estimators:\n",
    "    if not estimators[estimator]['rfe_possible']:\n",
    "        continue\n",
    "    else:\n",
    "        estimator_model = estimators[estimator]['model']\n",
    "        selector = RFE(estimator_model, n_features_to_select=15, step=10)\n",
    "        selector.fit(feature_selection_df, df['is_canceled'])\n",
    "        top_features[estimator] = feature_selection_df.columns[selector.support_].tolist()\n",
    "\n",
    "all_top_features = [e for l in [top_features[estimator] for estimator in top_features] for e in l]\n",
    "top_features['Highest Frequency'] = pd.Series(all_top_features).value_counts().iloc[:15].index.tolist()\n",
    "top_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 3.3 Model Performances\n",
    "With only the top 15 features left, we can now better compare the performances of the different models.\n",
    "\n",
    "In order to compare model performances, we define some standard functions we can apply. These functions will be used throughout the remainder of the notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.1 Logistic Regression, Random Forest, GXBoost & SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikf\\Desktop\\Master BA\\S2\\Machine Learning\\Hotel-Booking-ML\\venv\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:36:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "comparison_df = pd.DataFrame(index=metrics)\n",
    "fitted_models = []  # used for roc curve plot later\n",
    "X_test_sets = [] # used for roc curve plot later\n",
    "\n",
    "for model_name in estimators:\n",
    "    \"\"\"\n",
    "    if model == ann:\n",
    "        pred_proba = ann.predict(X_test.astype('float32'))[:,1]\n",
    "        model_pred = np.where(pred_proba > 0.5, 1,0)\n",
    "\n",
    "    else:\n",
    "        model_pred = model.predict(X_test)\n",
    "    \"\"\"\n",
    "    model_features = top_features[model_name] if estimators[model_name]['rfe_possible'] else top_features['Highest Frequency']\n",
    "    model = estimators[model_name]['model']\n",
    "    X_train_model = feature_selection_df[model_features]\n",
    "    y_train_model = df['is_canceled']\n",
    "    X_test_model = feature_selection_test_df[model_features]\n",
    "    y_test_model = df_test['is_canceled']\n",
    "\n",
    "    model.fit(X_train_model, y_train_model)\n",
    "    model_pred = model.predict(X_test_model)\n",
    "\n",
    "    accuracy = round(accuracy_score(y_test_model, model_pred), 4)\n",
    "    recall = round(recall_score(y_test_model, model_pred), 4)\n",
    "    precision = round(precision_score(y_test_model, model_pred), 4)\n",
    "    f1 = round(f1_score(y_test_model, model_pred), 4)\n",
    "\n",
    "    model_statistics = pd.DataFrame(index=metrics, data=[accuracy, precision, recall, f1], columns=[model_name])\n",
    "    comparison_df = comparison_df.join(model_statistics)\n",
    "\n",
    "    fitted_models.append(model)\n",
    "    X_test_sets.append(X_test_model)\n",
    "comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.2 Artificial Neural Network\n",
    "In addition to \"normal\" machine learning models, we also want to try an Artificial Neural Network. Since the process of training and predicting is different, in the following we will compute relevant metrics and append them to the previously computed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [34]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNum GPUs Available: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlist_physical_devices(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m'\u001B[39m)))\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "# Run this line only in case keras_tuner is not yet installed\n",
    "#!pip install -q -U keras-tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Defining a method that is used by the keras tuner later on\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(17,)))\n",
    "\n",
    "    # Tune the number of units in two Dense layers\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=512, step=32)\n",
    "    hp_units_2 = hp.Int('units_2', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units_1, activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=hp_units_2, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.1, 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 02m 03s]\n",
      "val_accuracy: 0.8177154660224915\n",
      "\n",
      "Best val_accuracy So Far: 0.8199664950370789\n",
      "Total elapsed time: 00h 24m 25s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3)\n",
    "tuner.search(X_train.astype('float32'), y_train.astype('float32'), epochs=50, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 288, for the second densely-connected layer is 160 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units_1')}, for the second densely-connected layer is {best_hps.get('units_2')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "ann = tuner.hypermodel.build(best_hps)\n",
    "history = ann.fit(X_train.astype('float32'),\n",
    "                    y_train.astype('float32'),\n",
    "                    epochs=50,\n",
    "                    validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_proba = ann.predict(X_test.astype('float32'))[:,1]\n",
    "model_pred = np.where(pred_proba > 0.5, 1,0)\n",
    "\n",
    "model_features = top_features['Highest Frequency']\n",
    "model = ann\n",
    "X_train_model = feature_selection_df[model_features]\n",
    "y_train_model = df['is_canceled']\n",
    "X_test_model = feature_selection_test_df[model_features]\n",
    "y_test_model = df_test['is_canceled']\n",
    "model.fit(X_train_model, y_train_model)\n",
    "\n",
    "pred_proba = ann.predict(X_test.astype('float32'))[:,1]\n",
    "model_pred = np.where(pred_proba > 0.5, 1,0)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test_model, model_pred), 4)\n",
    "recall = round(recall_score(y_test_model, model_pred), 4)\n",
    "precision = round(precision_score(y_test_model, model_pred), 4)\n",
    "f1 = round(f1_score(y_test_model, model_pred), 4)\n",
    "model_statistics = pd.DataFrame(index=metrics, data=[accuracy, precision, recall, f1], columns=[\"Artififical Neural Network\"])\n",
    "comparison_df = comparison_df.join(model_statistics)\n",
    "fitted_models.append(model)\n",
    "X_test_sets.append(X_test_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4 Model Comparison\n",
    "First, we look at the scores obtained:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importances_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the Random Forest model is the best model in for every metric except for recall (Logistic Regression performs best)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_roc_curve_multiple(models, X_test_in: Union[pd.DataFrame, List[pd.DataFrame]], y_true: pd.Series):\n",
    "    plt.figure(figsize=(6.4, 6), dpi=95)\n",
    "\n",
    "    #create ROC curve fpr each model\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        X_test = X_test_in[i] if isinstance(X_test_in, list) else X_test_in\n",
    "        if False: #model == ann:\n",
    "            y_pred_proba = ann.predict(X_test.astype('float32'))[:,1]\n",
    "        else:\n",
    "            y_pred_proba = model.predict_proba(X_test)[::,1]\n",
    "        fpr, tpr, _ = roc_curve(y_true,  y_pred_proba)\n",
    "        plt.plot(fpr, tpr, label=model.__class__.__name__)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linewidth=0.5, color='grey', label='Reference Line')  # plot diagonal as reference line\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.title('ROC Curve')\n",
    "\n",
    "get_roc_curve_multiple(fitted_models, X_test_sets, df_test['is_canceled'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selector = RFE(RandomForestClassifier(), n_features_to_select=15, step=10)\n",
    "feat_rank_df = pd.DataFrame(data=selector.ranking_, index=feature_selection_df.columns, columns=['rank']).sort_values('rank', ascending=True)\n",
    "feat_rank_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's look at the relative importance of the remaining 15 features in a Random Forest:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>numeric__lead_time</th>\n",
       "      <td>0.203632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__adr</th>\n",
       "      <td>0.137911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical__country_PRT</th>\n",
       "      <td>0.104149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__arrival_date_day_of_month</th>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__arrival_date_week_number</th>\n",
       "      <td>0.071397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__total_of_special_requests</th>\n",
       "      <td>0.069940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical__market_segment_Online TA</th>\n",
       "      <td>0.050861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__room_changed</th>\n",
       "      <td>0.042354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__stay_total_nights</th>\n",
       "      <td>0.041968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__previous_cancellations</th>\n",
       "      <td>0.039718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical__customer_type_Transient</th>\n",
       "      <td>0.038222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__arrival_date_month</th>\n",
       "      <td>0.037987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__stays_in_week_nights</th>\n",
       "      <td>0.032677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical__market_segment_Groups</th>\n",
       "      <td>0.024844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeric__stays_in_weekend_nights</th>\n",
       "      <td>0.020919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Importance\n",
       "numeric__lead_time                       0.203632\n",
       "numeric__adr                             0.137911\n",
       "categorical__country_PRT                 0.104149\n",
       "numeric__arrival_date_day_of_month       0.083421\n",
       "numeric__arrival_date_week_number        0.071397\n",
       "numeric__total_of_special_requests       0.069940\n",
       "categorical__market_segment_Online TA    0.050861\n",
       "numeric__room_changed                    0.042354\n",
       "numeric__stay_total_nights               0.041968\n",
       "numeric__previous_cancellations          0.039718\n",
       "categorical__customer_type_Transient     0.038222\n",
       "numeric__arrival_date_month              0.037987\n",
       "numeric__stays_in_week_nights            0.032677\n",
       "categorical__market_segment_Groups       0.024844\n",
       "numeric__stays_in_weekend_nights         0.020919"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_features = feature_selection_df.columns[selector.support_]\n",
    "feature_selection_remainder_df = feature_selection_df[remaining_features]\n",
    "rf_feature_selection = RandomForestClassifier()\n",
    "rf_feature_selection.fit(feature_selection_remainder_df, df['is_canceled'])\n",
    "importances_df = pd.DataFrame(data=rf_feature_selection.feature_importances_, index=remaining_features, columns=['Importance']).sort_values('Importance', ascending=False)\n",
    "importances_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances_df.sort_values('Importance', ascending=True).plot.barh()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Online TA        0.473667\n",
       "Offline TA/TO    0.203208\n",
       "Groups           0.165421\n",
       "Direct           0.105017\n",
       "Corporate        0.044269\n",
       "Complementary    0.006418\n",
       "Aviation         0.002000\n",
       "Name: market_segment, dtype: float64"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['market_segment'].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The two clearly most important features are the lead time and the average daily revenue (adr). The remaining features all have a pretty low, but balanced, importance that remains above the 2% mark."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Model Tuning\n",
    "### 4.1 Preprocessing Pipeline\n",
    "For the features chosen in 3.3, a preprocessing pipeline is built in which features get standardized or binarized."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Binarizer, FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Define categories of attributes\n",
    "num_attribs = [\"lead_time\", \"adr\", \"stay_total_nights\"]\n",
    "num_attribs_discr = [\"arrival_date_day_of_month\", \"arrival_date_month\", \"arrival_date_week_number\", \"room_changed\"]\n",
    "num_attribs_bin = [\"total_of_special_requests\", \"previous_cancellations\"]\n",
    "cat_attribs_bin = [\n",
    "    # (column, true value)\n",
    "    (\"country\", \"PRT\"),\n",
    "    (\"market_segment\", \"Online TA\"),\n",
    "    (\"market_segment\", \"Groups\"),\n",
    "    (\"customer_type\", \"Transient\")\n",
    "]\n",
    "\n",
    "# Create a class to select specified columns from DataFrame\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# Define function for one-vs-all binary transformation of categorical variables\n",
    "def binary_tansformer_cat(arr, true_vals):\n",
    "    # order of true_vals needs to be equivalent to corresponding column names in cat_attribs_bin\n",
    "    for i, true_val in enumerate(true_vals):\n",
    "        arr[:, i] = np.where(arr[:, i] == true_val, 1, 0)\n",
    "    return arr\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('selector', ColumnSelector(num_attribs)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "num_discrete_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('selector', ColumnSelector(num_attribs_discr))\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_binary_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('selector', ColumnSelector(num_attribs_bin)),\n",
    "        ('binarizer', Binarizer())\n",
    "    ])\n",
    "\n",
    "cat_binary_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('selector', ColumnSelector([e[0] for e in cat_attribs_bin])),\n",
    "        ('binarizer_cat', FunctionTransformer(binary_tansformer_cat, kw_args={'true_vals': [e[1] for e in cat_attribs_bin]}))\n",
    "    ])\n",
    "\n",
    "preprocessor = FeatureUnion(\n",
    "    transformer_list = [\n",
    "        ('num_pipeline', num_pipeline),\n",
    "        (\"num_discrete_pipeline\", num_discrete_pipeline),\n",
    "        (\"num_binary_pipeline\", num_binary_pipeline),\n",
    "        (\"cat_binary_pipeline\", cat_binary_pipeline),\n",
    "#        (\"cat_pipeline\", cat_pipeline)\n",
    "    ])\n",
    "preprocessor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Creation of X_train, y_train, X_test, y_test\n",
    "For the subsequent modeling, we need uniform datasets for training and testing data. Therefore, we split the existent 'df' (training data), 'df_test' (testing data) into X (features) and y (labels). The features are passed through the preprocessing pipeline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_config(display='text')\n",
    "X_train = preprocessor.fit_transform(df)\n",
    "y_train = df['is_canceled']\n",
    "X_test = preprocessor.fit_transform(df_test)\n",
    "y_test = df_test['is_canceled']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Standardized Model Evaluation\n",
    "We define several functions to evaluate a model. The aim is to have standardized functions to compare the various models on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, confusion_matrix, roc_curve\n",
    "import seaborn as sns\n",
    "\n",
    "def get_cnf_matrix(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function receives a true y and a predicted y array. It plots a confusion matrix as sns.heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true:\n",
    "            numpy array or pandas Series / DF of true y values. \n",
    "        y_pred:\n",
    "            numpy array or pandas Series / DF of predicted y values. \n",
    "    \"\"\"\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "\n",
    "    class_names=[0,1]\n",
    "    fig, ax = plt.subplots(figsize=(3.5,2.8), dpi=105)\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # create heatmap\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix),\n",
    "                annot=True,\n",
    "                cmap=\"YlGnBu\" ,\n",
    "                fmt='g',\n",
    "                )#annot_kws={\"size\": 15, \"weight\": \"bold\"})\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion Matrix', y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function receives a true y and a predicted y array. It prints Recall, Precision and Accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true:\n",
    "            numpy array or pandas Series / DF of true y values. \n",
    "        y_pred:\n",
    "            numpy array or pandas Series / DF of predicted y values. \n",
    "    \"\"\"\n",
    "    print(\"Recall:\", round(recall_score(y_true, y_pred),4))\n",
    "    print(\"Precision:\", round(precision_score(y_true, y_pred),4))\n",
    "    print(\"Accuracy:\", round(accuracy_score(y_true, y_pred),4))\n",
    "    print(\"F1 Score:\", round(f1_score(y_true, y_pred),4))\n",
    "\n",
    "\n",
    "def get_roc_curve(y_true, pred_proba):\n",
    "    y_pred_proba = pred_proba[::,1]\n",
    "    fpr, tpr, _ = roc_curve(y_true,  y_pred_proba)\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.figure(figsize=(4.3, 4), dpi=95)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], linewidth=0.5, color='grey') # plot diagonal as reference line\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "\n",
    "def get_roc_curve_ann(y_true, y_pred_proba):\n",
    "    fpr, tpr, _ = roc_curve(y_true,  y_pred_proba)\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.figure(figsize=(4.3, 4), dpi=95)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], linewidth=0.5, color='grey') # plot diagonal as reference line\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "\n",
    "def get_roc_curve_multiple(models, X_test, y_true):\n",
    "    plt.figure(figsize=(6.4, 6), dpi=95)\n",
    "\n",
    "    #create ROC curve fpr each model\n",
    "    for model in models:\n",
    "        if model == ann:\n",
    "            y_pred_proba = ann.predict(X_test.astype('float32'))[:,1]\n",
    "        else:\n",
    "            y_pred_proba = model.predict_proba(X_test)[::,1]\n",
    "        fpr, tpr, _ = roc_curve(y_true,  y_pred_proba)\n",
    "        plt.plot(fpr, tpr, label=model.__class__.__name__)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linewidth=0.5, color='grey', label='Reference Line')  # plot diagonal as reference line\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.title('ROC Curve')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 Models\n",
    "\n",
    "In the following we will test different models for the previously selected features. We will not be evaluating them based on a single business criterium/metric right now. Instead, we will use the overall confusion matrix, precision, recall and accuracy to get a feeling for the fit of a model to our problem. \n",
    "\n",
    "#### 4.4.1. Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "log_reg = LogisticRegression(class_weight = 'balanced',\n",
    "                             random_state = seed)\n",
    "\n",
    "params = {'C': [0.001, 0.01, 0.1, 1],\n",
    "          'solver' : ['liblinear', 'saga'],\n",
    "          'penalty': ['l1', 'l2']}\n",
    "\n",
    "RSCV = RandomizedSearchCV(log_reg,\n",
    "                          params,\n",
    "                          cv = 5,\n",
    "                          scoring = 'accuracy',\n",
    "                          return_train_score = True,\n",
    "                          n_jobs = -1,\n",
    "                          #n_iter = 20,\n",
    "                          random_state=42)\n",
    "\n",
    "\n",
    "search = RSCV.fit(X_train, y_train)\n",
    "results = pd.DataFrame(search.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_log_reg = search.best_estimator_\n",
    "best_log_reg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = best_log_reg.predict(X_test)\n",
    "pred_proba = best_log_reg.predict_proba(X_test)\n",
    "get_cnf_matrix(y_test, pred)\n",
    "get_metrics(y_test, pred)\n",
    "get_roc_curve(y_test, pred_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.2 Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=500,\n",
    "                                       random_state=42)\n",
    "param_grid = {'max_depth': [25],  #[15, 25],\n",
    "              'min_samples_split': [2],  #[2,5],\n",
    "              'min_samples_leaf': [1],  #[1,3]\n",
    "              'max_features': ['auto']}  #, 15, 12, 9]}\n",
    "gscv_rf = GridSearchCV(random_forest,\n",
    "                       param_grid=param_grid,\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "gscv_rf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_rf = gscv_rf.best_estimator_\n",
    "best_rf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = best_rf.predict(X_test)\n",
    "pred_proba = best_rf.predict_proba(X_test)\n",
    "get_cnf_matrix(y_test, pred)\n",
    "get_metrics(y_test, pred)\n",
    "get_roc_curve(y_test, pred_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_rf.feature_importances_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.3 XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv_params = {'max_depth': [5,7], 'min_child_weight': [1,3]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 500, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params),\n",
    "                             cv_params,\n",
    "                             scoring = 'accuracy',\n",
    "                             cv = 5,\n",
    "                             n_jobs = -1)\n",
    "optimized_GBM.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_xgb = optimized_GBM.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = best_xgb.predict(X_test)\n",
    "pred_proba = best_xgb.predict_proba(X_test)\n",
    "get_cnf_matrix(y_test, pred)\n",
    "get_metrics(y_test, pred)\n",
    "get_roc_curve(y_test, pred_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.X Voting Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', best_log_reg), ('rf', best_rf), ('xgb', best_xgb)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = voting_clf.predict(X_test)\n",
    "pred_proba = voting_clf.predict_proba(X_test)\n",
    "get_cnf_matrix(y_test, pred)\n",
    "get_metrics(y_test, pred)\n",
    "get_roc_curve(y_test, pred_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.5 Artificial Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "# Run this line only in case keras_tuner is not yet installed\n",
    "#!pip install -q -U keras-tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Defining a method that is used by the keras tuner later on\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(17,)))\n",
    "\n",
    "    # Tune the number of units in two Dense layers\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=512, step=32)\n",
    "    hp_units_2 = hp.Int('units_2', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units_1, activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=hp_units_2, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.1, 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3)\n",
    "tuner.search(X_train.astype('float32'), y_train.astype('float32'), epochs=50, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units_1')}, for the second densely-connected layer is {best_hps.get('units_2')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "ann = tuner.hypermodel.build(best_hps)\n",
    "history = ann.fit(X_train.astype('float32'), \n",
    "                    y_train.astype('float32'), \n",
    "                    epochs=50, \n",
    "                    validation_split=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_proba = ann.predict(X_test.astype('float32'))[:,1]\n",
    "pred = np.where(pred_proba > 0.5, 1,0)\n",
    "get_cnf_matrix(y_test, pred)\n",
    "get_metrics(y_test, pred)\n",
    "get_roc_curve_ann(y_test, pred_proba)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.5 Model Comparison\n",
    "In order to compare the different models developed before, a table comparing each of the obtained classification evaluation metrics is created."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "models = [best_log_reg, best_rf, best_xgb, voting_clf, ann]\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "comparison_df = pd.DataFrame(index=metrics)\n",
    "for model in models:\n",
    "    \n",
    "    if model == ann:\n",
    "        pred_proba = ann.predict(X_test.astype('float32'))[:,1]\n",
    "        model_pred = np.where(pred_proba > 0.5, 1,0)\n",
    "        \n",
    "    else:\n",
    "        model_pred = model.predict(X_test)\n",
    "        \n",
    "    accuracy = round(accuracy_score(y_test, model_pred), 4)\n",
    "    recall = round(recall_score(y_test, model_pred), 4)\n",
    "    precision = round(precision_score(y_test, model_pred), 4)\n",
    "    f1 = round(f1_score(y_test, model_pred), 4)\n",
    "\n",
    "    model_statistics = pd.DataFrame(index=metrics, data=[accuracy, precision, recall, f1], columns=[model.__class__.__name__])\n",
    "    comparison_df = comparison_df.join(model_statistics)\n",
    "comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the Random Forest model is the best model in for every metric except for recall (Logistic Regression performs best) and even outperforms the Voting Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_roc_curve_multiple(models, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ROC curves for all models look very well balanced towards the top left corner - as expected, the Random Forest Classifier also performs best in this aspect."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TO BE DELETED BEFORE SUBMISSION\n",
    "# used for trials with models / features\n",
    "\n",
    "#base_case_metrics = comparison_df.copy()\n",
    "#base_case_metrics.to_csv('base_case_metrics.csv')\n",
    "base_case_metrics = pd.read_csv('base_case_metrics.csv', index_col=0)\n",
    "comparison_df - base_case_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.6 Loading and saving of models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Saving models\n",
    "\n",
    "import joblib\n",
    "# save the model to disk\n",
    "models_to_save = [best_log_reg, best_rf, best_xgb, voting_clf, ann]\n",
    "all_filenames = []\n",
    "\n",
    "for model in models_to_save:\n",
    "    if model == ann:\n",
    "        ann.save('ann')\n",
    "    else: \n",
    "        label = model.__class__.__name__\n",
    "        filename = label + '.sav'\n",
    "        all_filenames.append(filename)\n",
    "        joblib.dump(model, filename)\n",
    "        print(label + \" saved\")\n",
    "joblib.dump(all_filenames ,\"filenames.sav\")\n",
    "print('\\nall models saved')\n",
    "\n",
    "# Loading the model again if needed\n",
    "#ann = tf.keras.models.load_model('ANN_model1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading Models\n",
    "\n",
    "all_filenames = joblib.load(\"filenames.sav\")\n",
    "\n",
    "best_log_reg = joblib.load(all_filenames[0])\n",
    "best_rf = joblib.load(all_filenames[1])\n",
    "best_xgb = joblib.load(all_filenames[2])\n",
    "voting_clf = joblib.load(all_filenames[3])\n",
    "ann = tf.keras.models.load_model('ann')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Business Case Calculation\n",
    "\n",
    "### 6.1 simple day based model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "df_eval_train = df_all[df_all['arrival_date'] < datetime.datetime(2017, 7, 1)]\n",
    "df_eval_test = df_all[df_all['arrival_date'] >= datetime.datetime(2017, 7, 1)]\n",
    "print(df_eval_train.shape)\n",
    "print(df_eval_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clustering_pipeline.fit(df_eval_train)\n",
    "df_eval_train['customer_cluster'] = clustering_pipeline.named_steps['kmeans'].labels_\n",
    "df_eval_train['customer_cluster'] = df_eval_train['customer_cluster'].astype(str)\n",
    "df_eval_test['customer_cluster'] = clustering_pipeline.predict(df_eval_test)\n",
    "df_eval_test['customer_cluster'] = df_eval_test['customer_cluster'].astype(str)\n",
    "\n",
    "X_train_eval = preprocessor.fit_transform(df_eval_train)\n",
    "y_train_eval = df_eval_train['is_canceled']\n",
    "X_test_eval = preprocessor.transform(df_eval_test)\n",
    "y_test_eval = df_eval_test['is_canceled']\n",
    "\n",
    "best_rf.fit(X_train_eval, y_train_eval)\n",
    "y_pred_eval = best_rf.predict(X_test_eval)\n",
    "df_eval_test['is_canceled_predicted'] = y_pred_eval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- If booking is canceled and we predict it correctly: + ADR from that booking\n",
    "- The False Positives and Negatives are summed up per day"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_profit = df_eval_test[['is_canceled', 'is_canceled_predicted', 'arrival_date','adr']]\n",
    "df_profit['correctly_classified'] = np.where((df_profit['is_canceled'] == df_profit['is_canceled_predicted']),\n",
    "                                             1,\n",
    "                                             0)\n",
    "df_profit['additional_adr'] = np.where((df_profit['is_canceled'] == 1) & (df_profit['correctly_classified'] == 1), \n",
    "                                       df_profit['adr'],\n",
    "                                       0) * 0.8\n",
    "display(df_profit)\n",
    "average_adr = df_profit.adr.mean()\n",
    "\n",
    "df_profit_agg = df_profit.groupby('arrival_date').sum()\n",
    "df_profit_agg['neg_adr_overbooking'] = df_profit_agg['is_canceled_predicted'] - df_profit_agg['is_canceled']\n",
    "df_profit_agg['neg_adr_overbooking'] = np.where(df_profit_agg['neg_adr_overbooking'] < 0, \n",
    "                                                0, \n",
    "                                                df_profit_agg['neg_adr_overbooking'])\n",
    "df_profit_agg['neg_adr_overbooking'] *= average_adr * 1.2\n",
    "df_profit_agg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round(df_profit_agg.additional_adr.sum() - df_profit_agg.neg_adr_overbooking.sum(),2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_profit.groupby('arrival_date').sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round(df_profit_agg.additional_adr.sum() - df_profit_agg.neg_adr_overbooking.sum(),2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_cnf_matrix(df_eval_test['is_canceled'], df_eval_test['is_canceled_predicted'])\n",
    "get_metrics(df_eval_test['is_canceled'], df_eval_test['is_canceled_predicted'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Appendix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1 ADR per Person\n",
    "We've seen that both the number of persons and the adr are features that influence whether a booking is cancelled or not. At the same time, adr is highly correlated with group size. Let's see if calculating the adr per person helps to explain cancellations as it removes the information captured in group size already.\n",
    "\n",
    "First, we construct different versions of the adr per person: One per guest (including babies and children) and one per adult. This way we ensure to test whether the pricing structure of the hotel also reflects whether children or babies are part of the guests."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_adr = df.copy()\n",
    "df_adr['adults'].replace({0: df_adr['adults'].median()}, inplace=True)\n",
    "df_adr['guests'].replace({0: df_adr['guests'].median()}, inplace=True)\n",
    "df_adr['adr_per_guest'] = df_adr['adr'] / df_adr['guests']\n",
    "df_adr['adr_per_adult'] = df_adr['adr'] / df_adr['adults']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see the correlation with is_cancelled for all versions and the original adr..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_adr[['adr', 'adr_per_guest', 'adr_per_adult', 'is_canceled']].corr()['is_canceled']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately, the adr per person does not help us more in explaining cancellations than the group adr does."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 K-Means clustering of customers\n",
    "In 3.2, it is striking that only few of the categorical features that depict the type of customer, such as the room in which they stay, the meal ordered, or the group size are part of the top 15 features. Let's have a closer look at how these features ranked in the recursive feature elimination:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "customer_attribs = ['guests', 'reserved_room_type', 'meal', 'stay_total_nights', 'is_family', 'hotel', 'distribution_channel', 'customer_type', 'is_repeated_guest']\n",
    "feat_rank_names = feat_rank_df.index.tolist()\n",
    "customer_attribs_mask = [any(customer_attrib in feat_name for customer_attrib in customer_attribs) for feat_name in feat_rank_names]\n",
    "feat_rank_df[customer_attribs_mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only 2 of the customer characteristics made it into the top 15. The rest got kicked out pretty early. The reason for this could be that these features contain that many sub-categories, that each sole subcategory does not explain cancellations sufficiently. There might still be the possibility that combined, these features *do* actually have relevance. In the following, we test this possibility by clustering customers based on their characteristics such as room type or meal and test, whether these clusters help to predict cancellations.\n",
    "\n",
    "First, we binarize the categorical features:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_df = df[customer_attribs]\n",
    "cluster_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols_to_binarize = cluster_df.columns[cluster_df.dtypes == 'object'].tolist()\n",
    "for col in cols_to_binarize:\n",
    "    dummy_cols = pd.get_dummies(cluster_df[col], prefix=col)\n",
    "    cluster_df = pd.concat([cluster_df, dummy_cols], axis=1)\n",
    "cluster_df.drop(columns=cols_to_binarize, axis=1, inplace=True)\n",
    "cluster_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we try different cluster sizes from 2 to 10 and observe the silhouette score obtained for each k:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "scores = []\n",
    "k_min = 2\n",
    "k_max = 10\n",
    "k_range = range(k_min, k_max+1)\n",
    "\n",
    "for k in tqdm(k_range):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=seed)\n",
    "    kmeans.fit(cluster_df)\n",
    "    labels = kmeans.labels_\n",
    "    score = silhouette_score(cluster_df, labels, metric = 'euclidean')\n",
    "    scores.append(score)\n",
    "plt.plot(k_range, scores, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Scores for Variations of k')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The resulting silhouette score is highest for k=2. This though would not help us much, since the resulting clusters would very likely only be split between city and resort hotel. Thus, we want to choose a higher k, that can reflect differences within each hotel type as well. In the following, we'll work with k=4.\n",
    "\n",
    "In order to understand the resulting clusters better, we can look at their sizes and the 'median customer' of each:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, n_init=30, max_iter=500, random_state=seed)\n",
    "kmeans.fit(cluster_df)\n",
    "pd.DataFrame(data=[pd.Series(kmeans.labels_).value_counts(), pd.Series(kmeans.labels_).value_counts(normalize=True)], index=['count', 'relative']).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "More than 80% of the customers are clustered in the top 2 clusters. The remaining clusters are very small, especially cluster 2 with only 1.4%.\n",
    "\n",
    "Let's have a look at how the median customer per cluster looks like:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_df['predicted_cluster'] = kmeans.labels_\n",
    "cluster_df.groupby('predicted_cluster').median()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clusters = cluster_df['predicted_cluster'].unique()\n",
    "for cluster in clusters:\n",
    "    cluster_data = cluster_df[cluster_df['predicted_cluster'] == cluster]\n",
    "    percent_of_total = cluster_data.shape[0] / cluster_df.shape[0]\n",
    "    print(f\"Cluster {cluster} ({round(percent_of_total*100, 2)}% of total):\")\n",
    "    for col in [c for c in cluster_data.columns if c != 'predicted_cluster']:\n",
    "        count = cluster_data[col].value_counts(normalize=True)\n",
    "        top_count = count.nlargest(1)\n",
    "        print(f\"\\t{col}: {top_count.index[0]} ({int(round(top_count.values[0]*100,0))}%)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we need to understand whether the clustering will improve our model performance. For simplicity, we only take the current best working model (Random Forest) and compare the obtained scores.\n",
    "\n",
    "First, we construct the pipeline for k-means clustering:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cust_cluster_attribs_num = ['guests', 'stay_total_nights']\n",
    "cust_cluster_attribs_bin = ['is_family', 'is_repeated_guest']\n",
    "cust_cluster_attribs_cat = ['reserved_room_type', 'meal', 'hotel', 'distribution_channel', 'customer_type']\n",
    "\n",
    "cluster_numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cluster_binary_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cluster_categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "clustering_preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', cluster_numeric_transformer, cust_cluster_attribs_num),\n",
    "        ('cat', cluster_categorical_transformer, cust_cluster_attribs_cat),\n",
    "        ('binary', cluster_binary_transformer, cust_cluster_attribs_bin)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clustering_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', clustering_preprocessing),\n",
    "        ('kmeans', KMeans(n_clusters=4, n_init=20, max_iter=500, random_state=seed))\n",
    "    ]\n",
    ")\n",
    "\n",
    "clustering_pipeline.fit(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we enrich the train set with clusters resulting from the previously constructed and fitted pipeline, and the test set with the predicted clusters from that pipeline:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cluster_performance_train = df.copy()\n",
    "df_cluster_performance_test = df_test.copy()\n",
    "df_cluster_performance_train['customer_cluster'] = clustering_pipeline.named_steps['kmeans'].labels_\n",
    "df_cluster_performance_test['customer_cluster'] = clustering_pipeline.predict(df_cluster_performance_test)\n",
    "#df_cluster_performance_train['customer_cluster'] = kmeans.labels_\n",
    "#df_cluster_performance_test['customer_cluster'] = kmeans.predict(truncator.transform(clustering_preprocessing.fit_transform(df_cluster_performance_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to compare the models, we need to include the customer clusters in our preprocessing pipeline. We do this by appending a pipeline that one-hot-encodes the clusters:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformers = preprocessor.transformer_list.copy()\n",
    "\n",
    "cluster_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('selector', ColumnSelector(['customer_cluster'])),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ]\n",
    ")\n",
    "transformers.append(('cluster_pipeline', cluster_pipeline))\n",
    "preprocessor_w_clustering = FeatureUnion(transformers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ready to go. Now we can get the train and test set and compare the performance of a model with and without customer clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_cluster = preprocessor_w_clustering.fit_transform(df_cluster_performance_train)\n",
    "y_train_cluster = df_cluster_performance_train['is_canceled']\n",
    "\n",
    "X_test_cluster = preprocessor_w_clustering.fit_transform(df_cluster_performance_test)\n",
    "y_test_cluster = df_cluster_performance_test['is_canceled']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "rf_original = clone(best_rf).fit(X_train, y_train)\n",
    "rf_cluster = clone(best_rf).fit(X_train_cluster, y_train_cluster)\n",
    "\n",
    "models = [rf_original, rf_cluster]\n",
    "model_names = ['Original', 'With Clusters']\n",
    "model_test_sets = [(X_test, y_test), (X_test_cluster, y_test_cluster)]\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "comparison_df = pd.DataFrame(index=metrics)\n",
    "for i, model in enumerate(models):\n",
    "    model_pred = model.predict(model_test_sets[i][0])\n",
    "    model_y_test = model_test_sets[i][1]\n",
    "    accuracy = round(accuracy_score(model_y_test, model_pred), 4)\n",
    "    recall = round(recall_score(model_y_test, model_pred), 4)\n",
    "    precision = round(precision_score(model_y_test, model_pred), 4)\n",
    "    f1 = round(f1_score(model_y_test, model_pred), 4)\n",
    "\n",
    "    model_statistics = pd.DataFrame(index=metrics, data=[accuracy, precision, recall, f1], columns=[model_names[i]])\n",
    "    comparison_df = comparison_df.join(model_statistics)\n",
    "comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model performance increased very, very slightly.\n",
    "\n",
    "Let's have a look at how important the clusters are for the predictions:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Importances: {rf_cluster.feature_importances_[-4:]}\")\n",
    "print(f\"Total: {round(sum(rf_cluster.feature_importances_[-4:])*100, 1)}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each of the resulting clusters added low importance (<=1%) to the model. Altogether, the clusters account for only ~2.7% of the model's feature importances."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Conclusion for Customer Clusters:**\n",
    "<br>Clustering the customers into clusters only helps to improve the model performance very slightly. At the same time, it adds additional computation time and complexity. Considering this, we will refrain from using customer clusters as features in the final model."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}